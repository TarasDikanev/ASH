{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Tokenize, lemmatize. Direct and inverted indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import json\n",
    "\n",
    "good = json.loads(open('D:\\\\AH3\\\\data\\\\processed\\\\an_good_eq.json', 'r', encoding = 'utf-8').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_list = ['когда-то', 'тогда-то', 'куда-то', 'откуда-то', 'туда-то', 'где-то', 'чей-то', 'какой-то', 'такой-то', 'который-то', \n",
    "           'как-то', 'так-то', 'зачем-то', 'всего-то', 'чего-то', 'отчего-то', 'сколько-то', 'то-то', 'кто-то', 'что-то', 'тот-то', \n",
    "           'тут-то', 'почему-то']\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text.lower(), language = 'russian')\n",
    "    tokens = [t for t in tokens if t not in (string.punctuation + \"''``«»\")]\n",
    "    tokens2 = []\n",
    "    for t in tokens:\n",
    "        if t[-3:] == '-то' and t not in to_list:\n",
    "            tokens2 += [t[:-3], '-то']\n",
    "        else:\n",
    "            tokens2 += [t]\n",
    "    return tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['глава',\n",
       " 'рпц',\n",
       " 'гундяев',\n",
       " 'рассуждает',\n",
       " 'о',\n",
       " 'здоровье',\n",
       " 'рубля',\n",
       " 'а',\n",
       " 'глава',\n",
       " 'минэкономразвития',\n",
       " 'улюкаев',\n",
       " 'о',\n",
       " 'духовном',\n",
       " 'здоровье',\n",
       " 'и',\n",
       " 'семейных',\n",
       " 'ценностях',\n",
       " 'нам',\n",
       " 'точно',\n",
       " 'кранты']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = good[100]\n",
    "\n",
    "tokens = tokenize(joke[0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize with pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = {\n",
    "    'лол': 'лол', 'белой': 'белый', 'хуясе': 'хуясе', 'джинса': 'джинса', 'гент': 'гент', 'ал': 'ал', \n",
    "    'але': 'але', 'алах': 'аллах', 'усы': 'усы', 'усе': 'усе', 'штоле': 'штоле', 'чето': 'чето', 'че': 'че', \n",
    "    'неее': 'неее', 'чтоле': 'чтоле', 'боков': 'бок', 'кароч': 'кароч', 'нете': 'нет_(сеть)', 'парней': 'парень',\n",
    "    'охуевшая': 'охуевший', 'охуевшей': 'охуевший', 'охуевшие': 'охуевший', 'охуевший': 'охуевший', \n",
    "    'охуевшим': 'охуевший', 'охуевшими': 'охуевший', 'охуевших': 'охуевший', 'ахуевшими': 'ахуевший', \n",
    "    'охуел': 'охуеть', 'охуела': 'охуеть', 'охуели': 'охуеть', 'спиздили': 'спиздить', 'долбоеб': 'долбоеб', \n",
    "    'долбоёб': 'долбоеб', 'хуею': 'хуеть', 'ебло': 'ебло', 'ебли': 'ебать'\n",
    "}\n",
    "\n",
    "postprocessing = {\n",
    "    'убунт': 'убунту', 'гент': 'генту', 'дебиана': 'дебиан', 'ктулха': 'ктулху', 'вист': 'виста', \n",
    "    'винд': 'винда', 'ютуба': 'ютуб', 'фич': 'фича', 'смайла': 'смайл', 'свича': 'свич', 'хабра': 'хабр', \n",
    "    'хабрахабра': 'хабрахабр', 'одмина': 'одмин', 'линуха': 'линух', 'хаба': 'хаб', 'пинга': 'пинг', \n",
    "    'конфига': 'конфиг', 'козлы': 'козёл', 'нихуй': 'нихуя', 'хуйн': 'хуйня', 'пидора': 'пидор', \n",
    "    'пидоров': 'пидор', 'пиздюля' : 'пиздюли', 'пидором': 'пидор', 'мудаки': 'мудак', 'мудаками': 'мудак', \n",
    "    'мудаком': 'мудак', 'мудака': 'мудак', 'заебал': 'заебать', 'съебал': 'съебать', 'доебал': 'доебать',\n",
    "    'проебали': 'проебать', 'проебал': 'проебать', 'разъебал': 'разъебать', 'заебали': 'заебать', \n",
    "    'ебали': 'ебать', 'уебали': 'уебать', 'ебал': 'ебать', 'выебал': 'выебать', 'наебал': 'наебать', \n",
    "    'сук': 'сука', 'херовин': 'херовина', 'херачил': 'херачить', 'херачили': 'херачить', 'захерачил': 'захерачить', \n",
    "    'отхерачил': 'отхерачить', 'херней': 'херня', 'дохер': 'дохера', 'отпиздим': 'отпиздить', \n",
    "    'спиздил': 'спиздить', 'насрало': 'насрать', 'дибить': 'дибил', 'ахуесть': 'ахуеть', 'пиздюля': 'пиздюли',\n",
    "    'ебета': 'ебать', 'ебут': 'ебать', 'серёг': 'серёга', 'матана': 'матан', 'игнора': 'игнор', 'ям': 'яма', \n",
    "    'джинса': 'джинсы', 'коты': 'кот', 'вейдёр': 'вейдер', 'побежалый': 'побежать', 'похуделый': 'похудеть', \n",
    "    'комаров': 'комар', 'маркета': 'маркет', 'трусик': 'трусики', 'медведа': 'медвед', 'охренель': 'охренеть',\n",
    "    'дот': 'дота', 'капёс': 'капс', 'винампа': 'винамп', 'ир': 'ира', 'анастасий': 'анастасия', 'марин': 'марина', \n",
    "    'дим': 'дима', 'димона': 'димон', 'красных': 'красный', 'поверь': 'поверить', 'живить': 'жить',\n",
    "    'печенек': 'печенька', 'тапка': 'тапок', 'игнора': 'игнор', 'донцов': 'донцова', 'скинхэда': 'скинхэд', \n",
    "    'скарлетта': 'скарлетт', 'боков': 'боковой', 'друган': 'друган', 'друганом': 'друган', 'другана': 'друган', \n",
    "    'мазд': 'мазда', 'каптать': 'капча', 'лежалый': 'лежать', 'оливья': 'оливье', 'парка': 'парк',\n",
    "    'орало': 'орать', 'охренела': 'охренеть', 'основный': 'основной', 'боев': 'боевой', 'тимлида': 'тимлид', \n",
    "    'млина': 'млин', 'вырасти': 'вырастать', 'фот': 'фота', 'другать': 'друган', 'фейспалма': 'фейспалм', \n",
    "    'погуглила': 'погуглить', 'погуголь': 'погугли', 'семейник': 'семейники', 'донестись': 'доноситься', \n",
    "    'тибить': 'тибя', 'уползти': 'уползать', 'смутиться': 'смущаться'\n",
    "}\n",
    "\n",
    "def lemmatize(token):\n",
    "    if token in exceptions:\n",
    "        lemma = exceptions[token]\n",
    "    else:\n",
    "        lemma = morph.parse(token)[0].normal_form\n",
    "        if lemma in postprocessing:\n",
    "            lemma = postprocessing[lemma]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['глава',\n",
       " 'рпц',\n",
       " 'гундяев',\n",
       " 'рассуждать',\n",
       " 'о',\n",
       " 'здоровье',\n",
       " 'рубль',\n",
       " 'а',\n",
       " 'глава',\n",
       " 'минэкономразвития',\n",
       " 'улюкай',\n",
       " 'о',\n",
       " 'духовный',\n",
       " 'здоровье',\n",
       " 'и',\n",
       " 'семейный',\n",
       " 'ценность',\n",
       " 'мы',\n",
       " 'точно',\n",
       " 'кранты']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = good[100]\n",
    "\n",
    "tokens = tokenize(joke[0])\n",
    "lemmas = [lemmatize(t) for t in tokens]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize with pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['глава',\n",
       " 'рпц',\n",
       " 'гундяев',\n",
       " 'рассуждать',\n",
       " 'о',\n",
       " 'здоровье',\n",
       " 'рубль',\n",
       " 'а',\n",
       " 'глава',\n",
       " 'минэкономразвития',\n",
       " 'улюкаев',\n",
       " 'о',\n",
       " 'духовный',\n",
       " 'здоровье',\n",
       " 'и',\n",
       " 'семейный',\n",
       " 'ценность',\n",
       " 'мы',\n",
       " 'точно',\n",
       " 'кранты']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()\n",
    "\n",
    "def lemmatize2(text):\n",
    "    lemmas = mystem.lemmatize(text.lower())\n",
    "    lemmas = [lemma for lemma in lemmas if \n",
    "                 lemma != ' ' and lemma != '\\n' and \\\n",
    "                 lemma.strip() not in (string.punctuation + \"''``«»\")]\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "lemmatize2(joke[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct and inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateIndex(jokes_list):\n",
    "    direct = []\n",
    "    inverted = {}\n",
    "    for i in range(len(jokes_list)):\n",
    "        joke = jokes_list[i]\n",
    "        tokens = tokenize(joke[0])\n",
    "        lemmas = [lemmatize(t) for t in tokens]\n",
    "        # direct index\n",
    "        lemmas_count = {}\n",
    "        for lemma in lemmas:\n",
    "            if lemma not in lemmas_count:\n",
    "                lemmas_count[lemma] = 1\n",
    "            else:\n",
    "                lemmas_count[lemma] += 1\n",
    "        direct.append(lemmas_count)\n",
    "        # inverted index\n",
    "        lemmas_count = {}\n",
    "        for lemma in lemmas:\n",
    "            if lemma not in inverted:\n",
    "                inverted[lemma] = [i]\n",
    "            else:\n",
    "                if lemma not in lemmas_count:\n",
    "                    inverted[lemma] += [i]\n",
    "                    lemmas_count[lemma] = 1\n",
    "    return direct, inverted\n",
    "\n",
    "\n",
    "import winsound\n",
    "\n",
    "an_good   = json.loads(open('D:\\\\AH3\\\\data\\\\processed\\\\an_good_eq.json', 'r', encoding = 'utf-8').read())\n",
    "an_bad    = json.loads(open('D:\\\\AH3\\\\data\\\\processed\\\\an_bad_eq.json', 'r', encoding = 'utf-8').read())\n",
    "bash_good = json.loads(open('D:\\\\AH3\\\\data\\\\processed\\\\bash_good_eq.json', 'r', encoding = 'utf-8').read())\n",
    "bash_bad  = json.loads(open('D:\\\\AH3\\\\data\\\\processed\\\\bash_bad_eq.json', 'r', encoding = 'utf-8').read())\n",
    "\n",
    "an_good_direct, an_good_inverted = CreateIndex(an_good)\n",
    "an_bad_direct, an_bad_inverted = CreateIndex(an_bad)\n",
    "bash_good_direct, bash_good_inverted = CreateIndex(bash_good)\n",
    "bash_bad_direct, bash_bad_inverted = CreateIndex(bash_bad)\n",
    "\n",
    "winsound.Beep(500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\an_good_direct.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(an_good_direct, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\an_bad_direct.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(an_bad_direct, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\an_good_inverted.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(an_good_inverted, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\an_bad_inverted.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(an_bad_inverted, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\bash_good_direct.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(bash_good_direct, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\bash_bad_direct.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(bash_bad_direct, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\bash_good_inverted.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(bash_good_inverted, ensure_ascii = False))\n",
    "f.close()\n",
    "f = open('D:\\\\AH3\\\\data\\\\interim\\\\bash_bad_inverted.json', 'w', encoding = 'utf-8')\n",
    "f.write(json.dumps(bash_bad_inverted, ensure_ascii = False))\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
